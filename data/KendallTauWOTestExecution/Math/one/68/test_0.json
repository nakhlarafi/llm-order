{
    "bug_id": 68,
    "test_id": 0,
    "test_name": "org.apache.commons.math.optimization.general.MinpackTest.testMinpackFreudensteinRoth",
    "test_body": "public void testMinpackFreudensteinRoth() {\nminpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n20.0124960961895, 6.99887517584575,\nnew double[] {\n11.4124844654993,\n-0.896827913731509\n}), false);\nminpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n12432.833948863, 6.9988751744895,\nnew double[] {\n11.4121122022341,\n-0.8968550851268697\n}), false);\nminpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n11426454.595762, 6.99887517242903,\nnew double[] {\n11.412069435091231,\n-0.8968582807605691\n}), false);\n}\n",
    "stack_trace": "junit.framework.AssertionFailedError: expected:<11.4121122022341> but was:<11.41300466147456>\nat junit.framework.Assert.fail(Assert.java:57)\nat junit.framework.Assert.failNotEquals(Assert.java:329)\nat junit.framework.Assert.assertEquals(Assert.java:120)\nat junit.framework.Assert.assertEquals(Assert.java:129)\nat junit.framework.TestCase.assertEquals(TestCase.java:288)\nat org.apache.commons.math.optimization.general.MinpackTest$MinpackFunction.checkTheoreticalMinParams(MinpackTest.java:575)\nat org.apache.commons.math.optimization.general.MinpackTest.minpackTest(MinpackTest.java:503)\nat org.apache.commons.math.optimization.general.MinpackTest.testMinpackFreudensteinRoth(MinpackTest.java:152)",
    "covered_methods": [
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:<init>()V",
            "method_body": "public LevenbergMarquardtOptimizer() {\n\n// set up the superclass with a default  max cost evaluations setting\nsetMaxIterations(1000);\n\n// default values for the tuning parameters\nsetInitialStepBoundFactor(100.0);\nsetCostRelativeTolerance(1.0e-10);\nsetParRelativeTolerance(1.0e-10);\nsetOrthoTolerance(1.0e-10);\n\n}",
            "method_id": 0
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:doOptimize()Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "protected VectorialPointValuePair doOptimize()\nthrows FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n// arrays shared with the other private methods\nsolvedCols  = Math.min(rows, cols);\ndiagR       = new double[cols];\njacNorm     = new double[cols];\nbeta        = new double[cols];\npermutation = new int[cols];\nlmDir       = new double[cols];\n\n// local point\ndouble   delta   = 0;\ndouble   xNorm   = 0;\ndouble[] diag    = new double[cols];\ndouble[] oldX    = new double[cols];\ndouble[] oldRes  = new double[rows];\ndouble[] work1   = new double[cols];\ndouble[] work2   = new double[cols];\ndouble[] work3   = new double[cols];\n\n// evaluate the function at the starting point and calculate its norm\nupdateResidualsAndCost();\n\n// outer loop\nlmPar = 0;\nboolean firstIteration = true;\nwhile (true) {\n\nincrementIterationsCounter();\n\n// compute the Q.R. decomposition of the jacobian matrix\nupdateJacobian();\nqrDecomposition();\n\n// compute Qt.res\nqTy(residuals);\n\n// now we don't need Q anymore,\n// so let jacobian contain the R matrix with its diagonal elements\nfor (int k = 0; k < solvedCols; ++k) {\nint pk = permutation[k];\njacobian[k][pk] = diagR[pk];\n}\n\nif (firstIteration) {\n\n// scale the point according to the norms of the columns\n// of the initial jacobian\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble dk = jacNorm[k];\nif (dk == 0) {\ndk = 1.0;\n}\ndouble xk = dk * point[k];\nxNorm  += xk * xk;\ndiag[k] = dk;\n}\nxNorm = Math.sqrt(xNorm);\n\n// initialize the step bound delta\ndelta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n}\n\n// check orthogonality between function vector and jacobian columns\ndouble maxCosine = 0;\nif (cost != 0) {\nfor (int j = 0; j < solvedCols; ++j) {\nint    pj = permutation[j];\ndouble s  = jacNorm[pj];\nif (s != 0) {\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += jacobian[i][pj] * residuals[i];\n}\nmaxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n}\n}\n}\nif (maxCosine <= orthoTolerance) {\n// convergence has been reached\nreturn new VectorialPointValuePair(point, objective);\n}\n\n// rescale if necessary\nfor (int j = 0; j < cols; ++j) {\ndiag[j] = Math.max(diag[j], jacNorm[j]);\n}\n\n// inner loop\nfor (double ratio = 0; ratio < 1.0e-4;) {\n\n// save the state\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\noldX[pj] = point[pj];\n}\ndouble previousCost = cost;\ndouble[] tmpVec = residuals;\nresiduals = oldRes;\noldRes    = tmpVec;\n\n// determine the Levenberg-Marquardt parameter\ndetermineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n// compute the new point and the norm of the evolution direction\ndouble lmNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nlmDir[pj] = -lmDir[pj];\npoint[pj] = oldX[pj] + lmDir[pj];\ndouble s = diag[pj] * lmDir[pj];\nlmNorm  += s * s;\n}\nlmNorm = Math.sqrt(lmNorm);\n\n// on the first iteration, adjust the initial step bound.\nif (firstIteration) {\ndelta = Math.min(delta, lmNorm);\n}\n\n// evaluate the function at x + p and calculate its norm\nupdateResidualsAndCost();\n\n// compute the scaled actual reduction\ndouble actRed = -1.0;\nif (0.1 * cost < previousCost) {\ndouble r = cost / previousCost;\nactRed = 1.0 - r * r;\n}\n\n// compute the scaled predicted reduction\n// and the scaled directional derivative\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble dirJ = lmDir[pj];\nwork1[j] = 0;\nfor (int i = 0; i <= j; ++i) {\nwork1[i] += jacobian[i][pj] * dirJ;\n}\n}\ndouble coeff1 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ncoeff1 += work1[j] * work1[j];\n}\ndouble pc2 = previousCost * previousCost;\ncoeff1 = coeff1 / pc2;\ndouble coeff2 = lmPar * lmNorm * lmNorm / pc2;\ndouble preRed = coeff1 + 2 * coeff2;\ndouble dirDer = -(coeff1 + coeff2);\n\n// ratio of the actual to the predicted reduction\nratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n// update the step bound\nif (ratio <= 0.25) {\ndouble tmp =\n(actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\nif ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\ntmp = 0.1;\n}\ndelta = tmp * Math.min(delta, 10.0 * lmNorm);\nlmPar /= tmp;\n} else if ((lmPar == 0) || (ratio >= 0.75)) {\ndelta = 2 * lmNorm;\nlmPar *= 0.5;\n}\n\n// test for successful iteration.\nif (ratio >= 1.0e-4) {\n// successful iteration, update the norm\nfirstIteration = false;\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble xK = diag[k] * point[k];\nxNorm    += xK * xK;\n}\nxNorm = Math.sqrt(xNorm);\n} else {\n// failed iteration, reset the previous values\ncost = previousCost;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\npoint[pj] = oldX[pj];\n}\ntmpVec    = residuals;\nresiduals = oldRes;\noldRes    = tmpVec;\n}\n\n// tests for convergence.\n// we use the vectorial convergence checker\n// we use the Levenberg-Marquardt specific convergence parameters\nif (((Math.abs(actRed) <= costRelativeTolerance) &&\n(preRed <= costRelativeTolerance) &&\n(ratio <= 2.0)) ||\n(delta <= parRelativeTolerance * xNorm)) {\nreturn new VectorialPointValuePair(point, objective);\n}\n\n// tests for termination and stringent tolerances\n// (2.2204e-16 is the machine epsilon for IEEE754)\nif ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\nthrow new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n\" no further reduction in the\" +\n\" sum of squares is possible\",\ncostRelativeTolerance);\n} else if (delta <= 2.2204e-16 * xNorm) {\nthrow new OptimizationException(\"parameters relative tolerance is too small\" +\n\" ({0}), no further improvement in\" +\n\" the approximate solution is possible\",\nparRelativeTolerance);\n} else if (maxCosine <= 2.2204e-16)  {\nthrow new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n\" solution is orthogonal to the jacobian\",\northoTolerance);\n}\n\n}\n\n}\n\n}",
            "method_id": 1
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:<init>()V",
            "method_body": "protected AbstractLeastSquaresOptimizer() {\nsetConvergenceChecker(new SimpleVectorialValueChecker());\nsetMaxIterations(DEFAULT_MAX_ITERATIONS);\nsetMaxEvaluations(Integer.MAX_VALUE);\n}",
            "method_id": 2
        },
        {
            "method_signature": "org.apache.commons.math.optimization.SimpleVectorialValueChecker:<init>()V",
            "method_body": "public SimpleVectorialValueChecker() {\nthis.relativeThreshold = DEFAULT_RELATIVE_THRESHOLD;\nthis.absoluteThreshold = DEFAULT_ABSOLUTE_THRESHOLD;\n}",
            "method_id": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:setInitialStepBoundFactor(D)V",
            "method_body": "public void setInitialStepBoundFactor(double initialStepBoundFactor) {\nthis.initialStepBoundFactor = initialStepBoundFactor;\n}",
            "method_id": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:setParRelativeTolerance(D)V",
            "method_body": "public void setParRelativeTolerance(double parRelativeTolerance) {\nthis.parRelativeTolerance = parRelativeTolerance;\n}",
            "method_id": 5
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qTy([D)V",
            "method_body": "private void qTy(double[] y) {\nfor (int k = 0; k < cols; ++k) {\nint pk = permutation[k];\ndouble gamma = 0;\nfor (int i = k; i < rows; ++i) {\ngamma += jacobian[i][pk] * y[i];\n}\ngamma *= beta[pk];\nfor (int i = k; i < rows; ++i) {\ny[i] -= gamma * jacobian[i][pk];\n}\n}\n}",
            "method_id": 6
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:updateResidualsAndCost()V",
            "method_body": "protected void updateResidualsAndCost()\nthrows FunctionEvaluationException {\n\nif (++objectiveEvaluations > maxEvaluations) {\nthrow new FunctionEvaluationException(new MaxEvaluationsExceededException(maxEvaluations),\npoint);\n}\nobjective = function.value(point);\nif (objective.length != rows) {\nthrow new FunctionEvaluationException(point, \"dimension mismatch {0} != {1}\",\nobjective.length, rows);\n}\ncost = 0;\nint index = 0;\nfor (int i = 0; i < rows; i++) {\nfinal double residual = targetValues[i] - objective[i];\nresiduals[i] = residual;\ncost += residualsWeights[i] * residual * residual;\nindex += cols;\n}\ncost = Math.sqrt(cost);\n\n}",
            "method_id": 7
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMParameter([DD[D[D[D[D)V",
            "method_body": "private void determineLMParameter(double[] qy, double delta, double[] diag,\ndouble[] work1, double[] work2, double[] work3) {\n\n// compute and store in x the gauss-newton direction, if the\n// jacobian is rank-deficient, obtain a least squares solution\nfor (int j = 0; j < rank; ++j) {\nlmDir[permutation[j]] = qy[j];\n}\nfor (int j = rank; j < cols; ++j) {\nlmDir[permutation[j]] = 0;\n}\nfor (int k = rank - 1; k >= 0; --k) {\nint pk = permutation[k];\ndouble ypk = lmDir[pk] / diagR[pk];\nfor (int i = 0; i < k; ++i) {\nlmDir[permutation[i]] -= ypk * jacobian[i][pk];\n}\nlmDir[pk] = ypk;\n}\n\n// evaluate the function at the origin, and test\n// for acceptance of the Gauss-Newton direction\ndouble dxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork1[pj] = s;\ndxNorm += s * s;\n}\ndxNorm = Math.sqrt(dxNorm);\ndouble fp = dxNorm - delta;\nif (fp <= 0.1 * delta) {\nlmPar = 0;\nreturn;\n}\n\n// if the jacobian is not rank deficient, the Newton step provides\n// a lower bound, parl, for the zero of the function,\n// otherwise set this bound to zero\ndouble sum2;\ndouble parl = 0;\nif (rank == solvedCols) {\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] *= diag[pj] / dxNorm;\n}\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i < j; ++i) {\nsum += jacobian[i][pj] * work1[permutation[i]];\n}\ndouble s = (work1[pj] - sum) / diagR[pj];\nwork1[pj] = s;\nsum2 += s * s;\n}\nparl = fp / (delta * sum2);\n}\n\n// calculate an upper bound, paru, for the zero of the function\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += jacobian[i][pj] * qy[i];\n}\nsum /= diag[pj];\nsum2 += sum * sum;\n}\ndouble gNorm = Math.sqrt(sum2);\ndouble paru = gNorm / delta;\nif (paru == 0) {\n// 2.2251e-308 is the smallest positive real for IEE754\nparu = 2.2251e-308 / Math.min(delta, 0.1);\n}\n\n// if the input par lies outside of the interval (parl,paru),\n// set par to the closer endpoint\nlmPar = Math.min(paru, Math.max(lmPar, parl));\nif (lmPar == 0) {\nlmPar = gNorm / dxNorm;\n}\n\nfor (int countdown = 10; countdown >= 0; --countdown) {\n\n// evaluate the function at the current value of lmPar\nif (lmPar == 0) {\nlmPar = Math.max(2.2251e-308, 0.001 * paru);\n}\ndouble sPar = Math.sqrt(lmPar);\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = sPar * diag[pj];\n}\ndetermineLMDirection(qy, work1, work2, work3);\n\ndxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork3[pj] = s;\ndxNorm += s * s;\n}\ndxNorm = Math.sqrt(dxNorm);\ndouble previousFP = fp;\nfp = dxNorm - delta;\n\n// if the function is small enough, accept the current value\n// of lmPar, also test for the exceptional cases where parl is zero\nif ((Math.abs(fp) <= 0.1 * delta) ||\n((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\nreturn;\n}\n\n// compute the Newton correction\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = work3[pj] * diag[pj] / dxNorm;\n}\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] /= work2[j];\ndouble tmp = work1[pj];\nfor (int i = j + 1; i < solvedCols; ++i) {\nwork1[permutation[i]] -= jacobian[i][pj] * tmp;\n}\n}\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ndouble s = work1[permutation[j]];\nsum2 += s * s;\n}\ndouble correction = fp / (delta * sum2);\n\n// depending on the sign of the function, update parl or paru.\nif (fp > 0) {\nparl = Math.max(parl, lmPar);\n} else if (fp < 0) {\nparu = Math.min(paru, lmPar);\n}\n\n// compute an improved estimate for lmPar\nlmPar = Math.max(parl, lmPar + correction);\n\n}\n}",
            "method_id": 8
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:setConvergenceChecker(Lorg/apache/commons/math/optimization/VectorialConvergenceChecker;)V",
            "method_body": "public void setConvergenceChecker(VectorialConvergenceChecker convergenceChecker) {\nthis.checker = convergenceChecker;\n}",
            "method_id": 9
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:optimize(Lorg/apache/commons/math/analysis/DifferentiableMultivariateVectorialFunction;[D[D[D)Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f,\nfinal double[] target, final double[] weights,\nfinal double[] startPoint)\nthrows FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\nif (target.length != weights.length) {\nthrow new OptimizationException(\"dimension mismatch {0} != {1}\",\ntarget.length, weights.length);\n}\n\n// reset counters\niterations           = 0;\nobjectiveEvaluations = 0;\njacobianEvaluations  = 0;\n\n// store least squares problem characteristics\nfunction         = f;\njF               = f.jacobian();\ntargetValues     = target.clone();\nresidualsWeights = weights.clone();\nthis.point       = startPoint.clone();\nthis.residuals   = new double[target.length];\n\n// arrays shared with the other private methods\nrows      = target.length;\ncols      = point.length;\njacobian  = new double[rows][cols];\n\ncost = Double.POSITIVE_INFINITY;\n\nreturn doOptimize();\n\n}",
            "method_id": 10
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:setOrthoTolerance(D)V",
            "method_body": "public void setOrthoTolerance(double orthoTolerance) {\nthis.orthoTolerance = orthoTolerance;\n}",
            "method_id": 11
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:setMaxIterations(I)V",
            "method_body": "public void setMaxIterations(int maxIterations) {\nthis.maxIterations = maxIterations;\n}",
            "method_id": 12
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:setMaxEvaluations(I)V",
            "method_body": "public void setMaxEvaluations(int maxEvaluations) {\nthis.maxEvaluations = maxEvaluations;\n}",
            "method_id": 13
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:setCostRelativeTolerance(D)V",
            "method_body": "public void setCostRelativeTolerance(double costRelativeTolerance) {\nthis.costRelativeTolerance = costRelativeTolerance;\n}",
            "method_id": 14
        },
        {
            "method_signature": "org.apache.commons.math.optimization.VectorialPointValuePair:<init>([D[D)V",
            "method_body": "public VectorialPointValuePair(final double[] point, final double[] value) {\nthis.point = point.clone();\nthis.value = value.clone();\n}",
            "method_id": 15
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qrDecomposition()V",
            "method_body": "private void qrDecomposition() throws OptimizationException {\n\n// initializations\nfor (int k = 0; k < cols; ++k) {\npermutation[k] = k;\ndouble norm2 = 0;\nfor (int i = 0; i < jacobian.length; ++i) {\ndouble akk = jacobian[i][k];\nnorm2 += akk * akk;\n}\njacNorm[k] = Math.sqrt(norm2);\n}\n\n// transform the matrix column after column\nfor (int k = 0; k < cols; ++k) {\n\n// select the column with the greatest norm on active components\nint nextColumn = -1;\ndouble ak2 = Double.NEGATIVE_INFINITY;\nfor (int i = k; i < cols; ++i) {\ndouble norm2 = 0;\nfor (int j = k; j < jacobian.length; ++j) {\ndouble aki = jacobian[j][permutation[i]];\nnorm2 += aki * aki;\n}\nif (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\nthrow new OptimizationException(\n\"unable to perform Q.R decomposition on the {0}x{1} jacobian matrix\",\nrows, cols);\n}\nif (norm2 > ak2) {\nnextColumn = i;\nak2        = norm2;\n}\n}\nif (ak2 == 0) {\nrank = k;\nreturn;\n}\nint pk                  = permutation[nextColumn];\npermutation[nextColumn] = permutation[k];\npermutation[k]          = pk;\n\n// choose alpha such that Hk.u = alpha ek\ndouble akk   = jacobian[k][pk];\ndouble alpha = (akk > 0) ? -Math.sqrt(ak2) : Math.sqrt(ak2);\ndouble betak = 1.0 / (ak2 - akk * alpha);\nbeta[pk]     = betak;\n\n// transform the current column\ndiagR[pk]        = alpha;\njacobian[k][pk] -= alpha;\n\n// transform the remaining columns\nfor (int dk = cols - 1 - k; dk > 0; --dk) {\ndouble gamma = 0;\nfor (int j = k; j < jacobian.length; ++j) {\ngamma += jacobian[j][pk] * jacobian[j][permutation[k + dk]];\n}\ngamma *= betak;\nfor (int j = k; j < jacobian.length; ++j) {\njacobian[j][permutation[k + dk]] -= gamma * jacobian[j][pk];\n}\n}\n\n}\n\nrank = solvedCols;\n\n}",
            "method_id": 16
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMDirection([D[D[D[D)V",
            "method_body": "private void determineLMDirection(double[] qy, double[] diag,\ndouble[] lmDiag, double[] work) {\n\n// copy R and Qty to preserve input and initialize s\n//  in particular, save the diagonal elements of R in lmDir\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nfor (int i = j + 1; i < solvedCols; ++i) {\njacobian[i][pj] = jacobian[j][permutation[i]];\n}\nlmDir[j] = diagR[pj];\nwork[j]  = qy[j];\n}\n\n// eliminate the diagonal matrix d using a Givens rotation\nfor (int j = 0; j < solvedCols; ++j) {\n\n// prepare the row of d to be eliminated, locating the\n// diagonal element using p from the Q.R. factorization\nint pj = permutation[j];\ndouble dpj = diag[pj];\nif (dpj != 0) {\nArrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n}\nlmDiag[j] = dpj;\n\n//  the transformations to eliminate the row of d\n// modify only a single element of Qty\n// beyond the first n, which is initially zero.\ndouble qtbpj = 0;\nfor (int k = j; k < solvedCols; ++k) {\nint pk = permutation[k];\n\n// determine a Givens rotation which eliminates the\n// appropriate element in the current row of d\nif (lmDiag[k] != 0) {\n\nfinal double sin;\nfinal double cos;\ndouble rkk = jacobian[k][pk];\nif (Math.abs(rkk) < Math.abs(lmDiag[k])) {\nfinal double cotan = rkk / lmDiag[k];\nsin   = 1.0 / Math.sqrt(1.0 + cotan * cotan);\ncos   = sin * cotan;\n} else {\nfinal double tan = lmDiag[k] / rkk;\ncos = 1.0 / Math.sqrt(1.0 + tan * tan);\nsin = cos * tan;\n}\n\n// compute the modified diagonal element of R and\n// the modified element of (Qty,0)\njacobian[k][pk] = cos * rkk + sin * lmDiag[k];\nfinal double temp = cos * work[k] + sin * qtbpj;\nqtbpj = -sin * work[k] + cos * qtbpj;\nwork[k] = temp;\n\n// accumulate the tranformation in the row of s\nfor (int i = k + 1; i < solvedCols; ++i) {\ndouble rik = jacobian[i][pk];\nfinal double temp2 = cos * rik + sin * lmDiag[i];\nlmDiag[i] = -sin * rik + cos * lmDiag[i];\njacobian[i][pk] = temp2;\n}\n\n}\n}\n\n// store the diagonal element of s and restore\n// the corresponding diagonal element of R\nlmDiag[j] = jacobian[j][permutation[j]];\njacobian[j][permutation[j]] = lmDir[j];\n\n}\n\n// solve the triangular system for z, if the system is\n// singular, then obtain a least squares solution\nint nSing = solvedCols;\nfor (int j = 0; j < solvedCols; ++j) {\nif ((lmDiag[j] == 0) && (nSing == solvedCols)) {\nnSing = j;\n}\nif (nSing < solvedCols) {\nwork[j] = 0;\n}\n}\nif (nSing > 0) {\nfor (int j = nSing - 1; j >= 0; --j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = j + 1; i < nSing; ++i) {\nsum += jacobian[i][pj] * work[i];\n}\nwork[j] = (work[j] - sum) / lmDiag[j];\n}\n}\n\n// permute the components of z back to components of lmDir\nfor (int j = 0; j < lmDir.length; ++j) {\nlmDir[permutation[j]] = work[j];\n}\n\n}",
            "method_id": 17
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:incrementIterationsCounter()V",
            "method_body": "protected void incrementIterationsCounter()\nthrows OptimizationException {\nif (++iterations > maxIterations) {\nthrow new OptimizationException(new MaxIterationsExceededException(maxIterations));\n}\n}",
            "method_id": 18
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:getRMS()D",
            "method_body": "public double getRMS() {\ndouble criterion = 0;\nfor (int i = 0; i < rows; ++i) {\nfinal double residual = residuals[i];\ncriterion += residualsWeights[i] * residual * residual;\n}\nreturn Math.sqrt(criterion / rows);\n}",
            "method_id": 19
        },
        {
            "method_signature": "org.apache.commons.math.optimization.VectorialPointValuePair:getPointRef()[D",
            "method_body": "public double[] getPointRef() {\nreturn point;\n}",
            "method_id": 20
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:updateJacobian()V",
            "method_body": "protected void updateJacobian() throws FunctionEvaluationException {\n++jacobianEvaluations;\njacobian = jF.value(point);\nif (jacobian.length != rows) {\nthrow new FunctionEvaluationException(point, \"dimension mismatch {0} != {1}\",\njacobian.length, rows);\n}\nfor (int i = 0; i < rows; i++) {\nfinal double[] ji = jacobian[i];\nfinal double factor = -Math.sqrt(residualsWeights[i]);\nfor (int j = 0; j < cols; ++j) {\nji[j] *= factor;\n}\n}\n}",
            "method_id": 21
        }
    ]
}