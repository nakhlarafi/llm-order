{
    "bug_id": 58,
    "test_id": 0,
    "test_name": "org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519",
    "test_body": "public void testMath519() {\n// The optimizer will try negative sigma values but \"GaussianFitter\"\n// will catch the raised exceptions and return NaN values instead.\nfinal double[] data = { \n1.1143831578403364E-29,\n4.95281403484594E-28,\n1.1171347211930288E-26,\n1.7044813962636277E-25,\n1.9784716574832164E-24,\n1.8630236407866774E-23,\n1.4820532905097742E-22,\n1.0241963854632831E-21,\n6.275077366673128E-21,\n3.461808994532493E-20,\n1.7407124684715706E-19,\n8.056687953553974E-19,\n3.460193945992071E-18,\n1.3883326374011525E-17,\n5.233894983671116E-17,\n1.8630791465263745E-16,\n6.288759227922111E-16,\n2.0204433920597856E-15,\n6.198768938576155E-15,\n1.821419346860626E-14,\n5.139176445538471E-14,\n1.3956427429045787E-13,\n3.655705706448139E-13,\n9.253753324779779E-13,\n2.267636001476696E-12,\n5.3880460095836855E-12,\n1.2431632654852931E-11\n};\nGaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\nfor (int i = 0; i < data.length; i++) {\nfitter.addObservedPoint(i, data[i]);\n}\nfinal double[] p = fitter.fit();\nAssert.assertEquals(53.1572792, p[1], 1e-7);\nAssert.assertEquals(5.75214622, p[2], 1e-8);\n}\n",
    "stack_trace": "org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than, or equal to, the minimum (0)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.validateParameters(Gaussian.java:183)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.value(Gaussian.java:128)\nat org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction.value(CurveFitter.java:203)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.computeObjectiveValue(BaseAbstractVectorialOptimizer.java:107)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.updateResidualsAndCost(AbstractLeastSquaresOptimizer.java:128)\nat org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer.doOptimize(LevenbergMarquardtOptimizer.java:350)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.optimize(BaseAbstractVectorialOptimizer.java:141)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:253)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:43)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:160)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:126)\nat org.apache.commons.math.optimization.fitting.GaussianFitter.fit(GaussianFitter.java:121)\nat org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519(GaussianFitterTest.java:336)",
    "covered_methods": [
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:doOptimize()Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "protected VectorialPointValuePair doOptimize() throws MathUserException {\n// arrays shared with the other private methods\nsolvedCols  = FastMath.min(rows, cols);\ndiagR       = new double[cols];\njacNorm     = new double[cols];\nbeta        = new double[cols];\npermutation = new int[cols];\nlmDir       = new double[cols];\n\n// local point\ndouble   delta   = 0;\ndouble   xNorm   = 0;\ndouble[] diag    = new double[cols];\ndouble[] oldX    = new double[cols];\ndouble[] oldRes  = new double[rows];\ndouble[] oldObj  = new double[rows];\ndouble[] qtf     = new double[rows];\ndouble[] work1   = new double[cols];\ndouble[] work2   = new double[cols];\ndouble[] work3   = new double[cols];\n\n// evaluate the function at the starting point and calculate its norm\nupdateResidualsAndCost();\n\n// outer loop\nlmPar = 0;\nboolean firstIteration = true;\nVectorialPointValuePair current = new VectorialPointValuePair(point, objective);\nint iter = 0;\nfinal ConvergenceChecker<VectorialPointValuePair> checker = getConvergenceChecker();\nwhile (true) {\n++iter;\n\nfor (int i=0;i<rows;i++) {\nqtf[i]=weightedResiduals[i];\n}\n\n// compute the Q.R. decomposition of the jacobian matrix\nVectorialPointValuePair previous = current;\nupdateJacobian();\nqrDecomposition();\n\n// compute Qt.res\nqTy(qtf);\n// now we don't need Q anymore,\n// so let jacobian contain the R matrix with its diagonal elements\nfor (int k = 0; k < solvedCols; ++k) {\nint pk = permutation[k];\nweightedResidualJacobian[k][pk] = diagR[pk];\n}\n\nif (firstIteration) {\n// scale the point according to the norms of the columns\n// of the initial jacobian\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble dk = jacNorm[k];\nif (dk == 0) {\ndk = 1.0;\n}\ndouble xk = dk * point[k];\nxNorm  += xk * xk;\ndiag[k] = dk;\n}\nxNorm = FastMath.sqrt(xNorm);\n\n// initialize the step bound delta\ndelta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n}\n\n// check orthogonality between function vector and jacobian columns\ndouble maxCosine = 0;\nif (cost != 0) {\nfor (int j = 0; j < solvedCols; ++j) {\nint    pj = permutation[j];\ndouble s  = jacNorm[pj];\nif (s != 0) {\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += weightedResidualJacobian[i][pj] * qtf[i];\n}\nmaxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * cost));\n}\n}\n}\nif (maxCosine <= orthoTolerance) {\n// convergence has been reached\nupdateResidualsAndCost();\ncurrent = new VectorialPointValuePair(point, objective);\nreturn current;\n}\n\n// rescale if necessary\nfor (int j = 0; j < cols; ++j) {\ndiag[j] = FastMath.max(diag[j], jacNorm[j]);\n}\n\n// inner loop\nfor (double ratio = 0; ratio < 1.0e-4;) {\n\n// save the state\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\noldX[pj] = point[pj];\n}\ndouble previousCost = cost;\ndouble[] tmpVec = weightedResiduals;\nweightedResiduals = oldRes;\noldRes    = tmpVec;\ntmpVec    = objective;\nobjective = oldObj;\noldObj    = tmpVec;\n\n// determine the Levenberg-Marquardt parameter\ndetermineLMParameter(qtf, delta, diag, work1, work2, work3);\n\n// compute the new point and the norm of the evolution direction\ndouble lmNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nlmDir[pj] = -lmDir[pj];\npoint[pj] = oldX[pj] + lmDir[pj];\ndouble s = diag[pj] * lmDir[pj];\nlmNorm  += s * s;\n}\nlmNorm = FastMath.sqrt(lmNorm);\n// on the first iteration, adjust the initial step bound.\nif (firstIteration) {\ndelta = FastMath.min(delta, lmNorm);\n}\n\n// evaluate the function at x + p and calculate its norm\nupdateResidualsAndCost();\n\n// compute the scaled actual reduction\ndouble actRed = -1.0;\nif (0.1 * cost < previousCost) {\ndouble r = cost / previousCost;\nactRed = 1.0 - r * r;\n}\n\n// compute the scaled predicted reduction\n// and the scaled directional derivative\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble dirJ = lmDir[pj];\nwork1[j] = 0;\nfor (int i = 0; i <= j; ++i) {\nwork1[i] += weightedResidualJacobian[i][pj] * dirJ;\n}\n}\ndouble coeff1 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ncoeff1 += work1[j] * work1[j];\n}\ndouble pc2 = previousCost * previousCost;\ncoeff1 = coeff1 / pc2;\ndouble coeff2 = lmPar * lmNorm * lmNorm / pc2;\ndouble preRed = coeff1 + 2 * coeff2;\ndouble dirDer = -(coeff1 + coeff2);\n\n// ratio of the actual to the predicted reduction\nratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n// update the step bound\nif (ratio <= 0.25) {\ndouble tmp =\n(actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\nif ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\ntmp = 0.1;\n}\ndelta = tmp * FastMath.min(delta, 10.0 * lmNorm);\nlmPar /= tmp;\n} else if ((lmPar == 0) || (ratio >= 0.75)) {\ndelta = 2 * lmNorm;\nlmPar *= 0.5;\n}\n\n// test for successful iteration.\nif (ratio >= 1.0e-4) {\n// successful iteration, update the norm\nfirstIteration = false;\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble xK = diag[k] * point[k];\nxNorm += xK * xK;\n}\nxNorm = FastMath.sqrt(xNorm);\ncurrent = new VectorialPointValuePair(point, objective);\n\n// tests for convergence.\nif (checker != null) {\n// we use the vectorial convergence checker\nif (checker.converged(iter, previous, current)) {\nreturn current;\n}\n}\n} else {\n// failed iteration, reset the previous values\ncost = previousCost;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\npoint[pj] = oldX[pj];\n}\ntmpVec    = weightedResiduals;\nweightedResiduals = oldRes;\noldRes    = tmpVec;\ntmpVec    = objective;\nobjective = oldObj;\noldObj    = tmpVec;\n}\n\n// Default convergence criteria.\nif ((FastMath.abs(actRed) <= costRelativeTolerance &&\npreRed <= costRelativeTolerance &&\nratio <= 2.0) ||\ndelta <= parRelativeTolerance * xNorm) {\nreturn current;\n}\n\n// tests for termination and stringent tolerances\n// (2.2204e-16 is the machine epsilon for IEEE754)\nif ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\nthrow new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\ncostRelativeTolerance);\n} else if (delta <= 2.2204e-16 * xNorm) {\nthrow new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\nparRelativeTolerance);\n} else if (maxCosine <= 2.2204e-16)  {\nthrow new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\northoTolerance);\n}\n}\n}\n}",
            "method_id": 0,
            "loc": 235
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMParameter([DD[D[D[D[D)V",
            "method_body": "private void determineLMParameter(double[] qy, double delta, double[] diag,\ndouble[] work1, double[] work2, double[] work3) {\n\n// compute and store in x the gauss-newton direction, if the\n// jacobian is rank-deficient, obtain a least squares solution\nfor (int j = 0; j < rank; ++j) {\nlmDir[permutation[j]] = qy[j];\n}\nfor (int j = rank; j < cols; ++j) {\nlmDir[permutation[j]] = 0;\n}\nfor (int k = rank - 1; k >= 0; --k) {\nint pk = permutation[k];\ndouble ypk = lmDir[pk] / diagR[pk];\nfor (int i = 0; i < k; ++i) {\nlmDir[permutation[i]] -= ypk * weightedResidualJacobian[i][pk];\n}\nlmDir[pk] = ypk;\n}\n\n// evaluate the function at the origin, and test\n// for acceptance of the Gauss-Newton direction\ndouble dxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork1[pj] = s;\ndxNorm += s * s;\n}\ndxNorm = FastMath.sqrt(dxNorm);\ndouble fp = dxNorm - delta;\nif (fp <= 0.1 * delta) {\nlmPar = 0;\nreturn;\n}\n\n// if the jacobian is not rank deficient, the Newton step provides\n// a lower bound, parl, for the zero of the function,\n// otherwise set this bound to zero\ndouble sum2;\ndouble parl = 0;\nif (rank == solvedCols) {\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] *= diag[pj] / dxNorm;\n}\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i < j; ++i) {\nsum += weightedResidualJacobian[i][pj] * work1[permutation[i]];\n}\ndouble s = (work1[pj] - sum) / diagR[pj];\nwork1[pj] = s;\nsum2 += s * s;\n}\nparl = fp / (delta * sum2);\n}\n\n// calculate an upper bound, paru, for the zero of the function\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += weightedResidualJacobian[i][pj] * qy[i];\n}\nsum /= diag[pj];\nsum2 += sum * sum;\n}\ndouble gNorm = FastMath.sqrt(sum2);\ndouble paru = gNorm / delta;\nif (paru == 0) {\n// 2.2251e-308 is the smallest positive real for IEE754\nparu = 2.2251e-308 / FastMath.min(delta, 0.1);\n}\n\n// if the input par lies outside of the interval (parl,paru),\n// set par to the closer endpoint\nlmPar = FastMath.min(paru, FastMath.max(lmPar, parl));\nif (lmPar == 0) {\nlmPar = gNorm / dxNorm;\n}\n\nfor (int countdown = 10; countdown >= 0; --countdown) {\n\n// evaluate the function at the current value of lmPar\nif (lmPar == 0) {\nlmPar = FastMath.max(2.2251e-308, 0.001 * paru);\n}\ndouble sPar = FastMath.sqrt(lmPar);\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = sPar * diag[pj];\n}\ndetermineLMDirection(qy, work1, work2, work3);\n\ndxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork3[pj] = s;\ndxNorm += s * s;\n}\ndxNorm = FastMath.sqrt(dxNorm);\ndouble previousFP = fp;\nfp = dxNorm - delta;\n\n// if the function is small enough, accept the current value\n// of lmPar, also test for the exceptional cases where parl is zero\nif ((FastMath.abs(fp) <= 0.1 * delta) ||\n((parl == 0) && (fp <= previousFP) && (previousFP < 0))) {\nreturn;\n}\n\n// compute the Newton correction\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = work3[pj] * diag[pj] / dxNorm;\n}\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] /= work2[j];\ndouble tmp = work1[pj];\nfor (int i = j + 1; i < solvedCols; ++i) {\nwork1[permutation[i]] -= weightedResidualJacobian[i][pj] * tmp;\n}\n}\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ndouble s = work1[permutation[j]];\nsum2 += s * s;\n}\ndouble correction = fp / (delta * sum2);\n\n// depending on the sign of the function, update parl or paru.\nif (fp > 0) {\nparl = FastMath.max(parl, lmPar);\n} else if (fp < 0) {\nparu = FastMath.min(paru, lmPar);\n}\n\n// compute an improved estimate for lmPar\nlmPar = FastMath.max(parl, lmPar + correction);\n\n}\n}",
            "method_id": 1,
            "loc": 148
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:exp(DD[D)D",
            "method_body": "private static double exp(double x, double extra, double[] hiPrec) {\ndouble intPartA;\ndouble intPartB;\nint intVal;\n\n/* Lookup exp(floor(x)).\n* intPartA will have the upper 22 bits, intPartB will have the lower\n* 52 bits.\n*/\nif (x < 0.0) {\nintVal = (int) -x;\n\nif (intVal > 746) {\nif (hiPrec != null) {\nhiPrec[0] = 0.0;\nhiPrec[1] = 0.0;\n}\nreturn 0.0;\n}\n\nif (intVal > 709) {\n/* This will produce a subnormal output */\nfinal double result = exp(x+40.19140625, extra, hiPrec) / 285040095144011776.0;\nif (hiPrec != null) {\nhiPrec[0] /= 285040095144011776.0;\nhiPrec[1] /= 285040095144011776.0;\n}\nreturn result;\n}\n\nif (intVal == 709) {\n/* exp(1.494140625) is nearly a machine number... */\nfinal double result = exp(x+1.494140625, extra, hiPrec) / 4.455505956692756620;\nif (hiPrec != null) {\nhiPrec[0] /= 4.455505956692756620;\nhiPrec[1] /= 4.455505956692756620;\n}\nreturn result;\n}\n\nintVal++;\n\nintPartA = EXP_INT_TABLE_A[750-intVal];\nintPartB = EXP_INT_TABLE_B[750-intVal];\n\nintVal = -intVal;\n} else {\nintVal = (int) x;\n\nif (intVal > 709) {\nif (hiPrec != null) {\nhiPrec[0] = Double.POSITIVE_INFINITY;\nhiPrec[1] = 0.0;\n}\nreturn Double.POSITIVE_INFINITY;\n}\n\nintPartA = EXP_INT_TABLE_A[750+intVal];\nintPartB = EXP_INT_TABLE_B[750+intVal];\n}\n\n/* Get the fractional part of x, find the greatest multiple of 2^-10 less than\n* x and look up the exp function of it.\n* fracPartA will have the upper 22 bits, fracPartB the lower 52 bits.\n*/\nfinal int intFrac = (int) ((x - intVal) * 1024.0);\nfinal double fracPartA = EXP_FRAC_TABLE_A[intFrac];\nfinal double fracPartB = EXP_FRAC_TABLE_B[intFrac];\n\n/* epsilon is the difference in x from the nearest multiple of 2^-10.  It\n* has a value in the range 0 <= epsilon < 2^-10.\n* Do the subtraction from x as the last step to avoid possible loss of percison.\n*/\nfinal double epsilon = x - (intVal + intFrac / 1024.0);\n\n/* Compute z = exp(epsilon) - 1.0 via a minimax polynomial.  z has\nfull double precision (52 bits).  Since z < 2^-10, we will have\n62 bits of precision when combined with the contant 1.  This will be\nused in the last addition below to get proper rounding. */\n\n/* Remez generated polynomial.  Converges on the interval [0, 2^-10], error\nis less than 0.5 ULP */\ndouble z = 0.04168701738764507;\nz = z * epsilon + 0.1666666505023083;\nz = z * epsilon + 0.5000000000042687;\nz = z * epsilon + 1.0;\nz = z * epsilon + -3.940510424527919E-20;\n\n/* Compute (intPartA+intPartB) * (fracPartA+fracPartB) by binomial\nexpansion.\ntempA is exact since intPartA and intPartB only have 22 bits each.\ntempB will have 52 bits of precision.\n*/\ndouble tempA = intPartA * fracPartA;\ndouble tempB = intPartA * fracPartB + intPartB * fracPartA + intPartB * fracPartB;\n\n/* Compute the result.  (1+z)(tempA+tempB).  Order of operations is\nimportant.  For accuracy add by increasing size.  tempA is exact and\nmuch larger than the others.  If there are extra bits specified from the\npow() function, use them. */\nfinal double tempC = tempB + tempA;\nfinal double result;\nif (extra != 0.0) {\nresult = tempC*extra*z + tempC*extra + tempC*z + tempB + tempA;\n} else {\nresult = tempC*z + tempB + tempA;\n}\n\nif (hiPrec != null) {\n// If requesting high precision\nhiPrec[0] = tempA;\nhiPrec[1] = tempC*extra*z + tempC*extra + tempC*z + tempB;\n}\n\nreturn result;\n}",
            "method_id": 2,
            "loc": 116
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMDirection([D[D[D[D)V",
            "method_body": "private void determineLMDirection(double[] qy, double[] diag,\ndouble[] lmDiag, double[] work) {\n\n// copy R and Qty to preserve input and initialize s\n//  in particular, save the diagonal elements of R in lmDir\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nfor (int i = j + 1; i < solvedCols; ++i) {\nweightedResidualJacobian[i][pj] = weightedResidualJacobian[j][permutation[i]];\n}\nlmDir[j] = diagR[pj];\nwork[j]  = qy[j];\n}\n\n// eliminate the diagonal matrix d using a Givens rotation\nfor (int j = 0; j < solvedCols; ++j) {\n\n// prepare the row of d to be eliminated, locating the\n// diagonal element using p from the Q.R. factorization\nint pj = permutation[j];\ndouble dpj = diag[pj];\nif (dpj != 0) {\nArrays.fill(lmDiag, j + 1, lmDiag.length, 0);\n}\nlmDiag[j] = dpj;\n\n//  the transformations to eliminate the row of d\n// modify only a single element of Qty\n// beyond the first n, which is initially zero.\ndouble qtbpj = 0;\nfor (int k = j; k < solvedCols; ++k) {\nint pk = permutation[k];\n\n// determine a Givens rotation which eliminates the\n// appropriate element in the current row of d\nif (lmDiag[k] != 0) {\n\nfinal double sin;\nfinal double cos;\ndouble rkk = weightedResidualJacobian[k][pk];\nif (FastMath.abs(rkk) < FastMath.abs(lmDiag[k])) {\nfinal double cotan = rkk / lmDiag[k];\nsin   = 1.0 / FastMath.sqrt(1.0 + cotan * cotan);\ncos   = sin * cotan;\n} else {\nfinal double tan = lmDiag[k] / rkk;\ncos = 1.0 / FastMath.sqrt(1.0 + tan * tan);\nsin = cos * tan;\n}\n\n// compute the modified diagonal element of R and\n// the modified element of (Qty,0)\nweightedResidualJacobian[k][pk] = cos * rkk + sin * lmDiag[k];\nfinal double temp = cos * work[k] + sin * qtbpj;\nqtbpj = -sin * work[k] + cos * qtbpj;\nwork[k] = temp;\n\n// accumulate the tranformation in the row of s\nfor (int i = k + 1; i < solvedCols; ++i) {\ndouble rik = weightedResidualJacobian[i][pk];\nfinal double temp2 = cos * rik + sin * lmDiag[i];\nlmDiag[i] = -sin * rik + cos * lmDiag[i];\nweightedResidualJacobian[i][pk] = temp2;\n}\n}\n}\n\n// store the diagonal element of s and restore\n// the corresponding diagonal element of R\nlmDiag[j] = weightedResidualJacobian[j][permutation[j]];\nweightedResidualJacobian[j][permutation[j]] = lmDir[j];\n}\n\n// solve the triangular system for z, if the system is\n// singular, then obtain a least squares solution\nint nSing = solvedCols;\nfor (int j = 0; j < solvedCols; ++j) {\nif ((lmDiag[j] == 0) && (nSing == solvedCols)) {\nnSing = j;\n}\nif (nSing < solvedCols) {\nwork[j] = 0;\n}\n}\nif (nSing > 0) {\nfor (int j = nSing - 1; j >= 0; --j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = j + 1; i < nSing; ++i) {\nsum += weightedResidualJacobian[i][pj] * work[i];\n}\nwork[j] = (work[j] - sum) / lmDiag[j];\n}\n}\n\n// permute the components of z back to components of lmDir\nfor (int j = 0; j < lmDir.length; ++j) {\nlmDir[permutation[j]] = work[j];\n}\n}",
            "method_id": 3,
            "loc": 100
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qrDecomposition()V",
            "method_body": "private void qrDecomposition() throws ConvergenceException {\n\n// initializations\nfor (int k = 0; k < cols; ++k) {\npermutation[k] = k;\ndouble norm2 = 0;\nfor (int i = 0; i < weightedResidualJacobian.length; ++i) {\ndouble akk = weightedResidualJacobian[i][k];\nnorm2 += akk * akk;\n}\njacNorm[k] = FastMath.sqrt(norm2);\n}\n\n// transform the matrix column after column\nfor (int k = 0; k < cols; ++k) {\n\n// select the column with the greatest norm on active components\nint nextColumn = -1;\ndouble ak2 = Double.NEGATIVE_INFINITY;\nfor (int i = k; i < cols; ++i) {\ndouble norm2 = 0;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\ndouble aki = weightedResidualJacobian[j][permutation[i]];\nnorm2 += aki * aki;\n}\nif (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\nthrow new ConvergenceException(LocalizedFormats.UNABLE_TO_PERFORM_QR_DECOMPOSITION_ON_JACOBIAN,\nrows, cols);\n}\nif (norm2 > ak2) {\nnextColumn = i;\nak2        = norm2;\n}\n}\nif (ak2 <= qrRankingThreshold) {\nrank = k;\nreturn;\n}\nint pk                  = permutation[nextColumn];\npermutation[nextColumn] = permutation[k];\npermutation[k]          = pk;\n\n// choose alpha such that Hk.u = alpha ek\ndouble akk   = weightedResidualJacobian[k][pk];\ndouble alpha = (akk > 0) ? -FastMath.sqrt(ak2) : FastMath.sqrt(ak2);\ndouble betak = 1.0 / (ak2 - akk * alpha);\nbeta[pk]     = betak;\n\n// transform the current column\ndiagR[pk]        = alpha;\nweightedResidualJacobian[k][pk] -= alpha;\n\n// transform the remaining columns\nfor (int dk = cols - 1 - k; dk > 0; --dk) {\ndouble gamma = 0;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\ngamma += weightedResidualJacobian[j][pk] * weightedResidualJacobian[j][permutation[k + dk]];\n}\ngamma *= betak;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\nweightedResidualJacobian[j][permutation[k + dk]] -= gamma * weightedResidualJacobian[j][pk];\n}\n}\n}\nrank = solvedCols;\n}",
            "method_id": 4,
            "loc": 66
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:createWeightedObservedPointComparator()Ljava/util/Comparator;",
            "method_body": "private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {\nreturn new Comparator<WeightedObservedPoint>() {\npublic int compare(WeightedObservedPoint p1, WeightedObservedPoint p2) {\nif (p1 == null && p2 == null) {\nreturn 0;\n}\nif (p1 == null) {\nreturn -1;\n}\nif (p2 == null) {\nreturn 1;\n}\nif (p1.getX() < p2.getX()) {\nreturn -1;\n}\nif (p1.getX() > p2.getX()) {\nreturn 1;\n}\nif (p1.getY() < p2.getY()) {\nreturn -1;\n}\nif (p1.getY() > p2.getY()) {\nreturn 1;\n}\nif (p1.getWeight() < p2.getWeight()) {\nreturn -1;\n}\nif (p1.getWeight() > p2.getWeight()) {\nreturn 1;\n}\nreturn 0;\n}\n};\n}",
            "method_id": 5,
            "loc": 34
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser$1:compare(Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;)I",
            "method_body": "private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {\nreturn new Comparator<WeightedObservedPoint>() {\npublic int compare(WeightedObservedPoint p1, WeightedObservedPoint p2) {\nif (p1 == null && p2 == null) {\nreturn 0;\n}\nif (p1 == null) {\nreturn -1;\n}\nif (p2 == null) {\nreturn 1;\n}\nif (p1.getX() < p2.getX()) {\nreturn -1;\n}\nif (p1.getX() > p2.getX()) {\nreturn 1;\n}\nif (p1.getY() < p2.getY()) {\nreturn -1;\n}\nif (p1.getY() > p2.getY()) {\nreturn 1;\n}\nif (p1.getWeight() < p2.getWeight()) {\nreturn -1;\n}\nif (p1.getWeight() > p2.getWeight()) {\nreturn 1;\n}\nreturn 0;\n}\n};\n}",
            "method_id": 6,
            "loc": 34
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:optimize(ILorg/apache/commons/math/analysis/MultivariateVectorialFunction;[D[D[D)Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "public VectorialPointValuePair optimize(int maxEval, FUNC f, double[] t, double[] w,\ndouble[] startPoint) {\n// Checks.\nif (f == null) {\nthrow new NullArgumentException();\n}\nif (t == null) {\nthrow new NullArgumentException();\n}\nif (w == null) {\nthrow new NullArgumentException();\n}\nif (startPoint == null) {\nthrow new NullArgumentException();\n}\nif (t.length != w.length) {\nthrow new DimensionMismatchException(t.length, w.length);\n}\n\n// Reset.\nevaluations.setMaximalCount(maxEval);\nevaluations.resetCount();\n\n// Store optimization problem characteristics.\nfunction = f;\ntarget = t.clone();\nweight = w.clone();\nstart = startPoint.clone();\n\n// Perform computation.\nreturn doOptimize();\n}",
            "method_id": 7,
            "loc": 32
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:getInterpolationPointsForY([Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;IID)[Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;",
            "method_body": "private WeightedObservedPoint[] getInterpolationPointsForY(WeightedObservedPoint[] points,\nint startIdx, int idxStep, double y)\nthrows OutOfRangeException {\nif (idxStep == 0) {\nthrow new ZeroException();\n}\nfor (int i = startIdx;\n(idxStep < 0) ? (i + idxStep >= 0) : (i + idxStep < points.length);\ni += idxStep) {\nif (isBetween(y, points[i].getY(), points[i + idxStep].getY())) {\nreturn (idxStep < 0) ?\nnew WeightedObservedPoint[] { points[i + idxStep], points[i] } :\nnew WeightedObservedPoint[] { points[i], points[i + idxStep] };\n}\n}\n\ndouble minY = Double.POSITIVE_INFINITY;\ndouble maxY = Double.NEGATIVE_INFINITY;\nfor (final WeightedObservedPoint point : points) {\nminY = Math.min(minY, point.getY());\nmaxY = Math.max(maxY, point.getY());\n}\nthrow new OutOfRangeException(y, minY, maxY);\n}",
            "method_id": 8,
            "loc": 24
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:optimize(ILorg/apache/commons/math/analysis/DifferentiableMultivariateVectorialFunction;[D[D[D)Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "public VectorialPointValuePair optimize(int maxEval,\nfinal DifferentiableMultivariateVectorialFunction f,\nfinal double[] target, final double[] weights,\nfinal double[] startPoint) {\n// Reset counter.\njacobianEvaluations = 0;\n\n// Store least squares problem characteristics.\njF = f.jacobian();\nthis.residuals = new double[target.length];\n\n// Arrays shared with the other private methods.\npoint = startPoint.clone();\nrows = target.length;\ncols = point.length;\n\nweightedResidualJacobian = new double[rows][cols];\nthis.weightedResiduals = new double[rows];\n\ncost = Double.POSITIVE_INFINITY;\n\nreturn super.optimize(maxEval, f, target, weights, startPoint);\n}",
            "method_id": 9,
            "loc": 23
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:basicGuess([Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;)[D",
            "method_body": "private double[] basicGuess(WeightedObservedPoint[] points) {\nArrays.sort(points, createWeightedObservedPointComparator());\ndouble[] params = new double[3];\n\nint maxYIdx = findMaxY(points);\nparams[0] = points[maxYIdx].getY();\nparams[1] = points[maxYIdx].getX();\n\ndouble fwhmApprox;\ntry {\ndouble halfY = params[0] + ((params[1] - params[0]) / 2.0);\ndouble fwhmX1 = interpolateXAtY(points, maxYIdx, -1, halfY);\ndouble fwhmX2 = interpolateXAtY(points, maxYIdx, +1, halfY);\nfwhmApprox = fwhmX2 - fwhmX1;\n} catch (OutOfRangeException e) {\nfwhmApprox = points[points.length - 1].getX() - points[0].getX();\n}\nparams[2] = fwhmApprox / (2.0 * Math.sqrt(2.0 * Math.log(2.0)));\n\nreturn params;\n}",
            "method_id": 10,
            "loc": 21
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:fit(ILorg/apache/commons/math/analysis/ParametricUnivariateRealFunction;[D)[D",
            "method_body": "public double[] fit(int maxEval, final ParametricUnivariateRealFunction f,\nfinal double[] initialGuess) {\n// prepare least squares problem\ndouble[] target  = new double[observations.size()];\ndouble[] weights = new double[observations.size()];\nint i = 0;\nfor (WeightedObservedPoint point : observations) {\ntarget[i]  = point.getY();\nweights[i] = point.getWeight();\n++i;\n}\n\n// perform the fit\nVectorialPointValuePair optimum =\noptimizer.optimize(maxEval, new TheoreticalValuesFunction(f),\ntarget, weights, initialGuess);\n\n// extract the coefficients\nreturn optimum.getPointRef();\n}",
            "method_id": 11,
            "loc": 20
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:updateResidualsAndCost()V",
            "method_body": "protected void updateResidualsAndCost() {\nobjective = computeObjectiveValue(point);\nif (objective.length != rows) {\nthrow new DimensionMismatchException(objective.length, rows);\n}\n\nfinal double[] targetValues = getTargetRef();\nfinal double[] residualsWeights = getWeightRef();\n\ncost = 0;\nint index = 0;\nfor (int i = 0; i < rows; i++) {\nfinal double residual = targetValues[i] - objective[i];\nweightedResiduals[i]= residual*FastMath.sqrt(residualsWeights[i]);\ncost += residualsWeights[i] * residual * residual;\nindex += cols;\n}\ncost = FastMath.sqrt(cost);\n}",
            "method_id": 12,
            "loc": 19
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:interpolateXAtY([Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;IID)D",
            "method_body": "private double interpolateXAtY(WeightedObservedPoint[] points,\nint startIdx, int idxStep, double y)\nthrows OutOfRangeException {\nif (idxStep == 0) {\nthrow new ZeroException();\n}\nWeightedObservedPoint[] twoPoints = getInterpolationPointsForY(points, startIdx, idxStep, y);\nWeightedObservedPoint pointA = twoPoints[0];\nWeightedObservedPoint pointB = twoPoints[1];\nif (pointA.getY() == y) {\nreturn pointA.getX();\n}\nif (pointB.getY() == y) {\nreturn pointB.getX();\n}\nreturn pointA.getX() +\n(((y - pointA.getY()) * (pointB.getX() - pointA.getX())) /\n(pointB.getY() - pointA.getY()));\n}",
            "method_id": 13,
            "loc": 19
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:max(DD)D",
            "method_body": "public static double max(final double a, final double b) {\nif (a > b) {\nreturn a;\n}\nif (a < b) {\nreturn b;\n}\n/* if either arg is NaN, return NaN */\nif (a != b) {\nreturn Double.NaN;\n}\n/* min(+0.0,-0.0) == -0.0 */\n/* 0x8000000000000000L == Double.doubleToRawLongBits(-0.0d) */\nlong bits = Double.doubleToRawLongBits(a);\nif (bits == 0x8000000000000000L) {\nreturn b;\n}\nreturn a;\n}",
            "method_id": 14,
            "loc": 19
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:min(DD)D",
            "method_body": "public static double min(final double a, final double b) {\nif (a > b) {\nreturn b;\n}\nif (a < b) {\nreturn a;\n}\n/* if either arg is NaN, return NaN */\nif (a != b) {\nreturn Double.NaN;\n}\n/* min(+0.0,-0.0) == -0.0 */\n/* 0x8000000000000000L == Double.doubleToRawLongBits(-0.0d) */\nlong bits = Double.doubleToRawLongBits(a);\nif (bits == 0x8000000000000000L) {\nreturn a;\n}\nreturn b;\n}",
            "method_id": 15,
            "loc": 19
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:updateJacobian()V",
            "method_body": "protected void updateJacobian() {\n++jacobianEvaluations;\nweightedResidualJacobian = jF.value(point);\nif (weightedResidualJacobian.length != rows) {\nthrow new DimensionMismatchException(weightedResidualJacobian.length, rows);\n}\n\nfinal double[] residualsWeights = getWeightRef();\n\nfor (int i = 0; i < rows; i++) {\nfinal double[] ji = weightedResidualJacobian[i];\ndouble wi = FastMath.sqrt(residualsWeights[i]);\nfor (int j = 0; j < cols; ++j) {\n//ji[j] *=  -1.0;\nweightedResidualJacobian[i][j] = -ji[j]*wi;\n}\n}\n}",
            "method_id": 16,
            "loc": 18
        },
        {
            "method_signature": "org.apache.commons.math.optimization.SimpleVectorialValueChecker:converged(ILorg/apache/commons/math/optimization/VectorialPointValuePair;Lorg/apache/commons/math/optimization/VectorialPointValuePair;)Z",
            "method_body": "public boolean converged(final int iteration,\nfinal VectorialPointValuePair previous,\nfinal VectorialPointValuePair current) {\nfinal double[] p = previous.getValueRef();\nfinal double[] c = current.getValueRef();\nfor (int i = 0; i < p.length; ++i) {\nfinal double pi         = p[i];\nfinal double ci         = c[i];\nfinal double difference = FastMath.abs(pi - ci);\nfinal double size       = FastMath.max(FastMath.abs(pi), FastMath.abs(ci));\nif (difference > size * getRelativeThreshold() &&\ndifference > getAbsoluteThreshold()) {\nreturn false;\n}\n}\nreturn true;\n}",
            "method_id": 17,
            "loc": 17
        },
        {
            "method_signature": "org.apache.commons.math.exception.util.ArgUtils:flatten([Ljava/lang/Object;)[Ljava/lang/Object;",
            "method_body": "public static Object[] flatten(Object[] array) {\nfinal List<Object> list = new ArrayList<Object>();\nif (array != null) {\nfor (Object o : array) {\nif (o instanceof Object[]) {\nfor (Object oR : flatten((Object[]) o)) {\nlist.add(oR);\n}\n} else {\nlist.add(o);\n}\n}\n}\nreturn list.toArray();\n}",
            "method_id": 18,
            "loc": 15
        },
        {
            "method_signature": "org.apache.commons.math.analysis.function.Gaussian$Parametric:gradient(D[D)[D",
            "method_body": "public double[] gradient(double x, double[] param) {\nvalidateParameters(param);\n\nfinal double norm = param[0];\nfinal double diff = x - param[1];\nfinal double sigma = param[2];\nfinal double i2s2 = 1 / (2 * sigma * sigma);\n\nfinal double n = Gaussian.value(diff, 1, i2s2);\nfinal double m = norm * n * 2 * i2s2 * diff;\nfinal double s = m * diff / sigma;\n\nreturn new double[] { n, m, s };\n}",
            "method_id": 19,
            "loc": 14
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction$1:value([D)[[D",
            "method_body": "public MultivariateMatrixFunction jacobian() {\nreturn new MultivariateMatrixFunction() {\npublic double[][] value(double[] point) {\nfinal double[][] jacobian = new double[observations.size()][];\n\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\njacobian[i++] = f.gradient(observed.getX(), point);\n}\n\nreturn jacobian;\n}\n};\n}",
            "method_id": 20,
            "loc": 14
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:jacobian()Lorg/apache/commons/math/analysis/MultivariateMatrixFunction;",
            "method_body": "public MultivariateMatrixFunction jacobian() {\nreturn new MultivariateMatrixFunction() {\npublic double[][] value(double[] point) {\nfinal double[][] jacobian = new double[observations.size()][];\n\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\njacobian[i++] = f.gradient(observed.getX(), point);\n}\n\nreturn jacobian;\n}\n};\n}",
            "method_id": 21,
            "loc": 14
        },
        {
            "method_signature": "org.apache.commons.math.exception.NumberIsTooSmallException:<init>(Lorg/apache/commons/math/exception/util/Localizable;Ljava/lang/Number;Ljava/lang/Number;Z)V",
            "method_body": "public NumberIsTooSmallException(Localizable specific,\nNumber wrong,\nNumber min,\nboolean boundIsAllowed) {\nsuper(specific,\nboundIsAllowed ?\nLocalizedFormats.NUMBER_TOO_SMALL :\nLocalizedFormats.NUMBER_TOO_SMALL_BOUND_EXCLUDED,\nwrong, min);\n\nthis.min = min;\nthis.boundIsAllowed = boundIsAllowed;\n}",
            "method_id": 22,
            "loc": 13
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qTy([D)V",
            "method_body": "private void qTy(double[] y) {\nfor (int k = 0; k < cols; ++k) {\nint pk = permutation[k];\ndouble gamma = 0;\nfor (int i = k; i < rows; ++i) {\ngamma += weightedResidualJacobian[i][pk] * y[i];\n}\ngamma *= beta[pk];\nfor (int i = k; i < rows; ++i) {\ny[i] -= gamma * weightedResidualJacobian[i][pk];\n}\n}\n}",
            "method_id": 23,
            "loc": 13
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:<init>(DDDDD)V",
            "method_body": "public LevenbergMarquardtOptimizer(double initialStepBoundFactor,\ndouble costRelativeTolerance,\ndouble parRelativeTolerance,\ndouble orthoTolerance,\ndouble threshold) {\nthis.initialStepBoundFactor = initialStepBoundFactor;\nthis.costRelativeTolerance = costRelativeTolerance;\nthis.parRelativeTolerance = parRelativeTolerance;\nthis.orthoTolerance = orthoTolerance;\nthis.qrRankingThreshold = threshold;\n}",
            "method_id": 24,
            "loc": 11
        },
        {
            "method_signature": "org.apache.commons.math.analysis.function.Gaussian$Parametric:validateParameters([D)V",
            "method_body": "private void validateParameters(double[] param) {\nif (param == null) {\nthrow new NullArgumentException();\n}\nif (param.length != 3) {\nthrow new DimensionMismatchException(param.length, 3);\n}\nif (param[2] <= 0) {\nthrow new NotStrictlyPositiveException(param[2]);\n}\n}",
            "method_id": 25,
            "loc": 11
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:value([D)[D",
            "method_body": "public double[] value(double[] point) {\n// compute the residuals\nfinal double[] values = new double[observations.size()];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\nvalues[i++] = f.value(observed.getX(), point);\n}\n\nreturn values;\n}",
            "method_id": 26,
            "loc": 10
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:findMaxY([Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;)I",
            "method_body": "private int findMaxY(WeightedObservedPoint[] points) {\nint maxYIdx = 0;\nfor (int i = 1; i < points.length; i++) {\nif (points[i].getY() > points[maxYIdx].getY()) {\nmaxYIdx = i;\n}\n}\nreturn maxYIdx;\n}",
            "method_id": 27,
            "loc": 9
        },
        {
            "method_signature": "org.apache.commons.math.exception.OutOfRangeException:<init>(Lorg/apache/commons/math/exception/util/Localizable;Ljava/lang/Number;Ljava/lang/Number;Ljava/lang/Number;)V",
            "method_body": "public OutOfRangeException(Localizable specific,\nNumber wrong,\nNumber lo,\nNumber hi) {\nsuper(specific, LocalizedFormats.OUT_OF_RANGE_SIMPLE,\nwrong, lo, hi);\nthis.lo = lo;\nthis.hi = hi;\n}",
            "method_id": 28,
            "loc": 9
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:<init>([Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;)V",
            "method_body": "public ParameterGuesser(WeightedObservedPoint[] observations) {\nif (observations == null) {\nthrow new NullArgumentException(LocalizedFormats.INPUT_ARRAY);\n}\nif (observations.length < 3) {\nthrow new NumberIsTooSmallException(observations.length, 3, true);\n}\nthis.observations = observations.clone();\n}",
            "method_id": 29,
            "loc": 9
        },
        {
            "method_signature": "org.apache.commons.math.exception.MathRuntimeException:<init>(Ljava/lang/Throwable;Lorg/apache/commons/math/exception/util/Localizable;Lorg/apache/commons/math/exception/util/Localizable;[Ljava/lang/Object;)V",
            "method_body": "public MathRuntimeException(final Throwable cause,\nfinal Localizable specific,\nfinal Localizable general,\nfinal Object ... arguments) {\nsuper(cause);\nthis.specific = specific;\nthis.general = general;\nthis.arguments = ArgUtils.flatten(arguments);\n}",
            "method_id": 30,
            "loc": 9
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction$1:<init>(Lorg/apache/commons/math/optimization/fitting/CurveFitter$TheoreticalValuesFunction;)V",
            "method_body": "public MultivariateMatrixFunction jacobian() {\nreturn new MultivariateMatrixFunction() {\nfinal double[][] jacobian = new double[observations.size()][];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\njacobian[i++] = f.gradient(observed.getX(), point);\nreturn jacobian;\n}",
            "method_id": 31,
            "loc": 8
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:computeObjectiveValue([D)[D",
            "method_body": "protected double[] computeObjectiveValue(double[] point) {\ntry {\nevaluations.incrementCount();\n} catch (MaxCountExceededException e) {\nthrow new TooManyEvaluationsException(e.getMax());\n}\nreturn function.value(point);\n}",
            "method_id": 32,
            "loc": 8
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser$1:compare(Ljava/lang/Object;Ljava/lang/Object;)I",
            "method_body": "private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {\nreturn new Comparator<WeightedObservedPoint>() {\nif (p1 == null && p2 == null) {\nif (p1 == null) {\nif (p2 == null) {\nif (p1.getX() < p2.getX()) {\nreturn -1;\n}",
            "method_id": 33,
            "loc": 8
        },
        {
            "method_signature": "org.apache.commons.math.analysis.function.Gaussian$Parametric:value(D[D)D",
            "method_body": "public double value(double x,\ndouble[] param) {\nvalidateParameters(param);\n\nfinal double diff = x - param[1];\nfinal double i2s2 = 1 / (2 * param[2] * param[2]);\nreturn Gaussian.value(diff, param[0], i2s2);\n}",
            "method_id": 34,
            "loc": 8
        },
        {
            "method_signature": "org.apache.commons.math.exception.MathIllegalNumberException:<init>(Lorg/apache/commons/math/exception/util/Localizable;Lorg/apache/commons/math/exception/util/Localizable;Ljava/lang/Number;[Ljava/lang/Object;)V",
            "method_body": "protected MathIllegalNumberException(Localizable specific,\nLocalizable general,\nNumber wrong,\nObject ... arguments) {\nsuper(specific, general, wrong, arguments);\nargument = wrong;\n}",
            "method_id": 35,
            "loc": 7
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:guess()[D",
            "method_body": "public double[] guess() {\nif (parameters == null) {\nparameters = basicGuess(observations);\n}\nreturn parameters.clone();\n}",
            "method_id": 36,
            "loc": 6
        },
        {
            "method_signature": "org.apache.commons.math.analysis.function.Gaussian:value(DDD)D",
            "method_body": "private static double value(double xMinusMean,\ndouble norm,\ndouble i2s2) {\nreturn norm * FastMath.exp(-xMinusMean * xMinusMean * i2s2);\n}",
            "method_id": 37,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.exception.MathIllegalArgumentException:<init>(Lorg/apache/commons/math/exception/util/Localizable;Lorg/apache/commons/math/exception/util/Localizable;[Ljava/lang/Object;)V",
            "method_body": "public MathIllegalArgumentException(Localizable specific,\nLocalizable general,\nObject ... args) {\nsuper(null, specific, general, args);\n}",
            "method_id": 38,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.exception.NumberIsTooSmallException:<init>(Ljava/lang/Number;Ljava/lang/Number;Z)V",
            "method_body": "public NumberIsTooSmallException(Number wrong,\nNumber min,\nboolean boundIsAllowed) {\nthis(null, wrong, min, boundIsAllowed);\n}",
            "method_id": 39,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:<init>(DDD)V",
            "method_body": "public WeightedObservedPoint(final double weight, final double x, final double y) {\nthis.weight = weight;\nthis.x      = x;\nthis.y      = y;\n}",
            "method_id": 40,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.util.Incrementor:incrementCount()V",
            "method_body": "public void incrementCount() {\nif (++count > maximalCount) {\nthrow new MaxCountExceededException(maximalCount);\n}\n}",
            "method_id": 41,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.exception.OutOfRangeException:<init>(Ljava/lang/Number;Ljava/lang/Number;Ljava/lang/Number;)V",
            "method_body": "public OutOfRangeException(Number wrong,\nNumber lo,\nNumber hi) {\nthis(null, wrong, lo, hi);\n}",
            "method_id": 42,
            "loc": 5
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter:fit()[D",
            "method_body": "public double[] fit() {\nfinal double[] guess = (new ParameterGuesser(getObservations())).guess();\nreturn fit(new Gaussian.Parametric(), guess);\n}",
            "method_id": 43,
            "loc": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.VectorialPointValuePair:<init>([D[D)V",
            "method_body": "public VectorialPointValuePair(final double[] point, final double[] value) {\nthis.point = (point == null) ? null : point.clone();\nthis.value = (value == null) ? null : value.clone();\n}",
            "method_id": 44,
            "loc": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:<init>(Lorg/apache/commons/math/optimization/DifferentiableMultivariateVectorialOptimizer;)V",
            "method_body": "public CurveFitter(final DifferentiableMultivariateVectorialOptimizer optimizer) {\nthis.optimizer = optimizer;\nobservations = new ArrayList<WeightedObservedPoint>();\n}",
            "method_id": 45,
            "loc": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:isBetween(DDD)Z",
            "method_body": "private boolean isBetween(double value, double boundary1, double boundary2) {\nreturn (value >= boundary1 && value <= boundary2) ||\n(value >= boundary2 && value <= boundary1);\n}",
            "method_id": 46,
            "loc": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:<init>()V",
            "method_body": "public AbstractConvergenceChecker() {\nthis.relativeThreshold = DEFAULT_RELATIVE_THRESHOLD;\nthis.absoluteThreshold = DEFAULT_ABSOLUTE_THRESHOLD;\n}",
            "method_id": 47,
            "loc": 4
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:<init>()V",
            "method_body": "public LevenbergMarquardtOptimizer() {\nthis(100, 1e-10, 1e-10, 1e-10, MathUtils.SAFE_MIN);\n}",
            "method_id": 48,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:<init>()V",
            "method_body": "protected BaseAbstractVectorialOptimizer() {\nthis(new SimpleVectorialValueChecker());\n}",
            "method_id": 49,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:getObservations()[Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;",
            "method_body": "public WeightedObservedPoint[] getObservations() {\nreturn observations.toArray(new WeightedObservedPoint[observations.size()]);\n}",
            "method_id": 50,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:<init>(Lorg/apache/commons/math/optimization/ConvergenceChecker;)V",
            "method_body": "protected BaseAbstractVectorialOptimizer(ConvergenceChecker<VectorialPointValuePair> checker) {\nthis.checker = checker;\n}",
            "method_id": 51,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:addObservedPoint(DD)V",
            "method_body": "public void addObservedPoint(double x, double y) {\naddObservedPoint(1.0, x, y);\n}",
            "method_id": 52,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:<init>(Lorg/apache/commons/math/optimization/fitting/CurveFitter;Lorg/apache/commons/math/analysis/ParametricUnivariateRealFunction;)V",
            "method_body": "public TheoreticalValuesFunction(final ParametricUnivariateRealFunction f) {\nthis.f = f;\n}",
            "method_id": 53,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.Incrementor:setMaximalCount(I)V",
            "method_body": "public void setMaximalCount(int max) {\nmaximalCount = max;\n}",
            "method_id": 54,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter:<init>(Lorg/apache/commons/math/optimization/DifferentiableMultivariateVectorialOptimizer;)V",
            "method_body": "public GaussianFitter(DifferentiableMultivariateVectorialOptimizer optimizer) {\nsuper(optimizer);\n}",
            "method_id": 55,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:getTargetRef()[D",
            "method_body": "protected double[] getTargetRef() {\nreturn target;\n}",
            "method_id": 56,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getWeight()D",
            "method_body": "public double getWeight() {\nreturn weight;\n}",
            "method_id": 57,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:fit(Lorg/apache/commons/math/analysis/ParametricUnivariateRealFunction;[D)[D",
            "method_body": "public double[] fit(final ParametricUnivariateRealFunction f, final double[] initialGuess) {\nreturn fit(Integer.MAX_VALUE, f, initialGuess);\n}",
            "method_id": 58,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getX()D",
            "method_body": "public double getX() {\nreturn x;\n}",
            "method_id": 59,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:exp(D)D",
            "method_body": "public static double exp(double x) {\nreturn exp(x, 0.0, null);\n}",
            "method_id": 60,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:abs(D)D",
            "method_body": "public static double abs(double x) {\nreturn (x < 0.0) ? -x : (x == 0.0) ? 0.0 : x; // -0.0 => +0.0\n}",
            "method_id": 61,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:sqrt(D)D",
            "method_body": "public static double sqrt(final double a) {\nreturn Math.sqrt(a);\n}",
            "method_id": 62,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.Incrementor:resetCount()V",
            "method_body": "public void resetCount() {\ncount = 0;\n}",
            "method_id": 63,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:getWeightRef()[D",
            "method_body": "protected double[] getWeightRef() {\nreturn weight;\n}",
            "method_id": 64,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:getAbsoluteThreshold()D",
            "method_body": "public double getAbsoluteThreshold() {\nreturn absoluteThreshold;\n}",
            "method_id": 65,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:getConvergenceChecker()Lorg/apache/commons/math/optimization/ConvergenceChecker;",
            "method_body": "public ConvergenceChecker<VectorialPointValuePair> getConvergenceChecker() {\nreturn checker;\n}",
            "method_id": 66,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:getRelativeThreshold()D",
            "method_body": "public double getRelativeThreshold() {\nreturn relativeThreshold;\n}",
            "method_id": 67,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.exception.NotStrictlyPositiveException:<init>(Ljava/lang/Number;)V",
            "method_body": "public NotStrictlyPositiveException(Number value) {\nsuper(value, 0, false);\n}",
            "method_id": 68,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.util.FastMath:min(II)I",
            "method_body": "public static int min(final int a, final int b) {\nreturn (a <= b) ? a : b;\n}",
            "method_id": 69,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.VectorialPointValuePair:getValueRef()[D",
            "method_body": "public double[] getValueRef() {\nreturn value;\n}",
            "method_id": 70,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:addObservedPoint(DDD)V",
            "method_body": "public void addObservedPoint(double weight, double x, double y) {\nobservations.add(new WeightedObservedPoint(weight, x, y));\n}",
            "method_id": 71,
            "loc": 3
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getY()D",
            "method_body": "public double getY() {\nreturn y;\n}",
            "method_id": 72,
            "loc": 3
        }
    ]
}